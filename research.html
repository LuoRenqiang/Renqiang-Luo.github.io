
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="shortcut icon" href="research_books_22128.ico">
    <link rel="stylesheet" type="text/css" href="style.css" />
    <!-- <link rel="shortcut icon" href="research_books_22128.ico"> -->
    <title>Researcher's Research</title>
    <!-- <base href="./index.html"> -->

</head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<h1 style="padding-left: 0.5em">Researcher </h1><hr>
<td id="layout-menu">
    <div class="menu-item"><a href="index.html">Home</a></div>
    <div class="menu-item"><a href="groups.html">Group</a></div>
    <div class="menu-item"><a href="teaching.html">Teaching</a></div>
    <div class="menu-item"><a href="service.html">Service</a></div>
    <div class="menu-item"><a href="research.html">Research</a></div>
    <div class="menu-item"><a href="publications.html">Publications</a></div>
    <div class="menu-item"><a href="code.html">Codes & Data</a></div>
    <div class="menu-item"><a href="award.html">Awards & honours</a></div>
</td>
<td id="layout-content">

    <h1 style="margin-top: 0em">Research</h1>

    <p style="font-style: italic; margin-bottom: 30px;">
        My research lies at the intersection of machine learning methodology and trustworthy AI systems, focusing on fairness, privacy and explainability of algorithms.
        <br>
        Interested in joining the team? See our <a href="groups.html">Group page</a> for open positions.
    </p>

    <h2 style="color: #00796B;">&#x1F578;&#xFE0F; Theme 1: Algorithmic Fairness</h2>
    <p>
        My work aims to build <strong>fairness Graph Neural Networks (GNNs)</strong> that are unbiased to different gender, race, region etc.
    </p>
    <ul style="list-style-type: disc;">
        <li><strong>Key Focus:</strong> Designing GNN architectures that maintain performance under fairness-aware.</li>
        <li><strong>Recent Projects:</strong> Developing <strong>fairness-aware encoding</strong> for enhancing Graph Transformer fairness; <strong>spectral analysis</strong> for harmonizing fairness and utility in GNNs.</li>
    </ul>
    
    <div style="margin-top: 15px; padding: 10px; background-color: #E0F2F1; border-left: 4px solid #00796B;">
        &#x1F4C3; <strong>Related Publications:</strong> [<a href="https://www.ijcai.org/proceedings/2024/0050.pdf">FairGT: A Fairness-aware Graph Transformer</a>] | 
        [<a href="https://dl.acm.org/doi/abs/10.1145/3637528.3671834">FUGNN: Harmonizing Fairness and Utility in Graph Neural Networks</a>]
    </div>

    <hr>

   <h2 style="color: #D32F2F;">&#x2696;&#xFE0F; Theme 2: Algorithmic Privacy</h2> 
    <p> 
        Focusing on robustness and security of AI, especially Multimodal Transformers, in high-stakes domains like healthcare. This stream addresses vulnerabilities, such as backdoor attacks, to ensure the integrity and reliability of AI-driven patient prognosis systems. 
    </p> 
    <ul style="list-style-type: disc;"> 
        <li>Key Focus: Enhancing the security of Multimodal Transformers (ViT) for disease prognosis against backdoor threats in integrated clinical data.</li> 
        <li>Recent Projects: Proposing RMTrans, a robust multimodal framework; developing a patch-based processing method to mitigate trigger over-fitting and enhance global feature learning.</li> </ul>
    
    <div style="margin-top: 15px; padding: 10px; background-color: #FFEBEE; border-left: 4px solid #D32F2F;">
        &#x1F4C3; <strong>Related Publications:</strong> [<a href="https://dl.acm.org/doi/abs/10.1145/3749989">RMTrans: Robust Multimodal Transformers for Patient Prognosis under Backdoor Threats</a>] 
    </div>

    <hr>

    <h2 style="color: #D32F2F;">&#x2696;&#xFE0F; Theme 3: Algorithmic Explainability</h2> 
    <p> 
        Comprehensible neural network explanations are crucial for decision-making, especially when models face malicious perturbations. This research addresses the limitations of adversarial training by developing a method to generate interpretable and logical explanations even under unknown perturbations, ensuring explanations align with real-world logic. 
    </p> 
    <ul style="list-style-type: disc;"> 
        <li>Key Focus: Designing the AGAIN (fActor GrAph-based Interpretable neural Network) framework to generate comprehensible explanations under unknown perturbations by directly integrating logical rules during inference.</li> 
        <li>Recent Projects: Constructing a factor graph to express logical rules and identify/rectify logical errors in explanations; proposing an interactive intervention switch strategy for rectification without perturbation retraining.</li> </ul>
    
    <div style="margin-top: 15px; padding: 10px; background-color: #FFEBEE; border-left: 4px solid #D32F2F;"> 
        &#x1F4C3; <strong>Related Publications:</strong> [<a href="https://openreview.net/forum?id=10DtLPsdro">Factor Graph-based Interpretable Neural Networks</a>]
    </div>

</td>
</tr>
</table>
<footer style="text-align: center; margin-top: 20px; color: #666;">
<p>&copy; 2025</p>
</footer>
</body>
</html>
